Summary:
## News / Update
Global AI governance took center stage at the UN Security Council, where Yoshua Bengio urged evidence-based guardrails for advanced AI and Stanford HAI called for equitable access so benefits reach billions, not just a few. In industry moves, Google DeepMind unveiled Gemini Robotics 1.5 and Robotics‑ER 1.5, pushing embodied reasoning and tool use toward general-purpose robots. Infrastructure and capital flows accelerated: CoreWeave expanded its OpenAI partnership by $6.5B, NVIDIA advanced hybrid quantum computing with CUDA‑Q and DGX Quantum, and NVIDIA’s Cosmos Reason surpassed 1 million downloads for agent and robot reasoning. Perplexity launched a high-speed Search API for real-time answers, while Tencent Hunyuan teased a leading open-source text-to-image model. Funding continued across the stack, including FactoryAI’s $50M for coding agents and Scorecard’s $3.75M for automated model evaluation. The ecosystem also saw shifts toward AMD hardware (e.g., full fine-tuning of a 4.5B-parameter medical model on MI300X and rapid workload migration via TensorWave and Modular), community momentum around DSPy, and a new AI Council at Unity to guide next-gen game development.

## New Tools
Developer and creator tooling expanded rapidly. GitHub launched Copilot CLI in public preview for terminal-based coding and deployment, while Perplexity’s new Search API offers millisecond-level, real-time results to power agents and LLM apps. Groq introduced Remote MCP for plug-and-play tool integration with fast, OpenAI-compatible inference; LMCache delivered smart cross-device KV caching to speed up inference; and Suno Studio debuted as a generative audio workstation for end-to-end AI music creation. Lightweight and accessible options proliferated: tiny task-specific models now run on Raspberry Pi; Nemotron became easier to run locally on RTX PCs; and zml_ai’s sparse logarithmic attention promised “unlimited” context on CPUs. Evaluation tools matured with lighteval v0.11.0 and AA‑WER for robust speech-to-text benchmarking. New build accelerators included a drop-in UI component library for chat/agent apps, Kimi’s website-building agent from a single prompt, ShinkaEvolve for LLM-driven program evolution in science, and one-click access to massive vision-language models via Hugging Face’s Inference Providers (e.g., Qwen3‑VL).

## LLMs
A wave of benchmarks and model advances clarified the state of play. OpenAI’s GDPval benchmark evaluates models on economically valuable real-world tasks across 44 occupations; Anthropic’s Claude 4.1 Opus led the pack and even outperformed financial experts in targeted tests, underscoring near-expert capability on practical work. Google previewed Gemini 2.5 Flash and Flash‑Lite with notable gains in intelligence, speed, and token efficiency. Meta’s Code World Model (32B) targets deeper code reasoning via agentic simulation, while Google’s EmbeddingGemma (300M) achieved SOTA embeddings at tiny scale. Vision-language and multilingual capabilities advanced with Qwen3‑VL becoming easy to try and MamayLM v1.0 adding strong image input and long context in Ukrainian and English. Research highlights included ByteDance’s CASTLE for more adaptive attention, a scalable “soft tokens” RL approach enabling richer continuous reasoning, and OpenAI’s report of a rare large-scale pretraining breakthrough. Databricks showed prompt optimization (GEPA) can match or beat supervised fine-tuning at a fraction of the cost. Training diversity grew as a 4.5B-parameter medical model was fully fine-tuned on AMD MI300X, signaling credible non‑NVIDIA pathways for high-end workloads.

## Features
AI assistants became more proactive and enterprise-ready. OpenAI introduced ChatGPT Pulse for daily personalized updates on mobile, highlighted a broader shift toward goal-oriented assistance, and rolled out Business features like shared projects, connectors, and role-based access control. Google launched Gemini Live for more natural, native-audio conversations and expanded access to Gemini Code Assist and CLI with higher limits. Developer productivity saw upgrades with GitHub Copilot’s improved code search via a new embedding model and Conductor’s Claude-powered auto-fix for failing GitHub Actions. Creative workflows tightened as FLUX.1 Kontext [Pro] integrated directly into Photoshop and Meta’s “Vibes” offered a short-form, AI-generated video feed; artists also showcased Photoshop’s Generative Fill to turn quick sketches into polished scenes.

## Tutorials & Guides
Hands-on resources emphasized practical understanding and reproducibility. Deep dives unpacked high-performance Triton kernels and the design of fast softmax attention, while Perplexity openly detailed the evaluation stack behind its new Search API. A full guide showed how to animate characters from a single photo with Wan 2.2, and Booking.com shared how it built an AI Trip Planner on top of OpenAI for richer, more conversational trip design. Together, these resources demystify core kernels, evaluation practices, and end-to-end product construction.

## Showcases & Demos
Robotics and creative media demos highlighted what’s now possible. Developers ran local LLMs and VLMs on a humanoid (Pepper) via Ollama, a generalist system assembled Lego builds from visual input alone, and Pollen Robotics’ Reachy Mini took the stage for a live demo. On the media side, Kling 2.5’s frame chaining enabled effectively infinite video, often paired with AI-generated music, while a compact model generated playable game worlds (TinyWorlds). New experiences let listeners “chat” with a guest’s digital persona after a podcast, and researchers reported emergent zero-shot skills in video models (e.g., Veo3). Artists continued to turn rough sketches into finished environments using modern generative fill.

## Discussions & Ideas
Transparency and evaluation fairness dominated discourse after Anthropic shared a routing bug postmortem that distorted results, prompting calls for level playing fields and credit where due—including praise for OpenAI highlighting a rival’s success. Roboticists argued that flashy demos must be backed by code, data, and reproducibility. Product and UX debates surfaced around hiding system prompts and tool specs from power users. Practitioners noted that prompt optimization can deliver better, cheaper results than fine-tuning in many cases. Several threads examined the gap between early automation predictions and reality—radiology hasn’t been displaced despite years of benchmark wins—while others explored whether video models are nearing a “GPT moment.” Broader visions included OpenAI’s aim for an automated researcher capable of independent discovery and renewed interest in open-ended algorithms to drive scientific breakthroughs. Market watchers weighed the durability of fast-growing AI revenues, and researchers contrasted human mental execution of code with current LLMs’ logical limits. Equity remained a theme, with calls at the UN to ensure global access to AI’s benefits.

## Memes & Humor
The business of virality got serious: a startup raised $3M to industrialize meme creation, underscoring how internet culture and creator tools are becoming investable product categories in their own right.

