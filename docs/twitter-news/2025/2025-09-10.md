Summary:
## News / Update
Major funding and industry momentum led the week. Mistral AI raised roughly €1.7B (~$2B) at a ~$13.7B valuation to accelerate open-weight model development, while Cognition secured over $400M at a ~$10.2B valuation and is now valued near $10B. Sphinx Copilot raised $9.5M as it launches its data science agent. Partnerships and deployments expanded: Mayo Clinic is applying AI to genomics and pathology for personalized diagnostics; Hugging Face teamed with Mattt to push on-device AI; BMW advanced autonomous driving with Qualcomm; and OpenAI backed an animated AI film project. Codex now accounts for about a third of platform agent sessions. Google unveiled an AI system that writes expert-level scientific software. Research and community activity stayed brisk, with highlighted paper roundups and AgentScope 1.0 trending, plus numerous events: a San Francisco agent hackathon, GPU Mode’s return, a London agent-focused summit, VS Code Dev Days worldwide, and an Unsloth AMA. Recognition also grew for safety research as Neel Nanda was named to MIT Tech Review’s Innovators Under 35. Additional notes include a medical AI internship opportunity at FLAIR and strong robotics headlines from Google DeepMind and others.

## New Tools
A wave of developer tools and templates landed to speed AI workflows. Firecrawl enables natural-language website scraping; Codex CLI automates migrations from legacy Chat Completions APIs; Helicone offers open-source observability across model requests; and Modal’s GPU Notebooks bring collaborative, browser-based experimentation with rapid GPU swaps. RAGGY introduced a purpose-built REPL for rapid RAG iteration, while WebExplorer released a data-generation framework for training long-horizon web agents. Creative and vision tools expanded with ToonOut for anime background removal and Higgsfield’s Banana Placement for precise product inpainting. Robotics builders can now deploy with an all-in-one, AI-native dev kit, and Bruno shipped a git-native API client as a VS Code extension. Pydantic AI plus Logfire showcased typed agents with end-to-end tracing, and the official MCP Server Registry launched as a trusted directory for server components. An open-source “Video Generation Studio” template helps teams compose video workflows with Veo and Imagen. Sphinx Copilot also exited beta with a production-ready data science agent.

## LLMs
Model innovation continued across scale, efficiency, and modalities. Alibaba unveiled Qwen3-Max (>1T parameters), while DeepSeek’s “Gated Attention” architecture scaled to 1T parameters in Qwen3-Next. Baidu’s ERNIE 4.5-21B emphasized compact reasoning strength; Qwen3-Next-80B also arrived. K2-Think (32B) was released on Hugging Face, targeting advanced reasoning with efficiency claims rivaling much larger models. ModernBERT launched a multilingual encoder covering ~1,800 languages and introduced practical token-level hallucination detection, while Gemma 3n brought open on-device audio support. Speech advances included Bilibili’s IndexTTS2 with state-of-the-art autoregressive control. Performance and inference research surged: KV cache compression and quantization techniques are making inference cheaper; HICRA boosted math and reasoning accuracy; and TraceRL introduced a reinforcement learning framework (and TraDo-4B/8B models) for diffusion-based LLMs. Datasets like FineWeb2 are powering new general-purpose models. Market dynamics reflected rapid progress from affordable coding models (e.g., GLM-4.5, Kimi K2.x) and reports of small models outperforming much larger ones, while Grok-code-fast-1 showed strong gains in code editing. Long-context experiments advanced with stealth models offering up to 2M tokens.

## Features
Existing products gained meaningful capabilities aimed at speed, control, and creation. Meta’s REFRAG plugin significantly expands RAG context and lowers latency for faster, higher-recall retrieval. Anthropic rolled out a sandboxed code interpreter and direct file creation/editing, turning chats into spreadsheets, documents, slides, and PDFs; Claude Web makes coding features accessible without a dev setup. LangChain introduced Agent Middleware (and an Agent Hub via Warden) to fine-tune agent behavior and monetize agents; LangGraph and LangChain reached 1.0. Weights & Biases added support for GLM-4.5 (300B). LlamaCloud expanded parsing to 50+ complex document types and now lets users mix and match extraction models. LangSmith added org-scoped API keys for better team control. Jules now accepts image uploads for instant visual feedback. NotebookLM introduced student-focused features like flashcards, quizzes, and learning guides. Gemini Canvas added “Select and Ask” for point-and-click UI edits. Minions integrated with Docker’s model runner for easier local deployment. In creative media, Google’s Veo 3 brought 1080p and vertical video with substantial price cuts via the Gemini API, Runway expanded availability to web and iOS, and Kling introduced keyframe-based cinematic transitions. In healthcare, Glass launched ambient clinical decision support with real-time mobile AI. A persistent pain point remains: ChatGPT voice uploads still time out around two minutes for long inputs. Some apps also rolled out time-limited free “effects” to spur experimentation.

## Tutorials & Guides
Hands-on learning resources proliferated. A detailed guide showed how to fine-tune Gemini to audit Terraform for security and detect phishing end-to-end. Hugging Face released a free fine-tuning course with certification that covers instruction tuning, reinforcement learning, evaluation, and synthetic data creation. Technical explainers broke down KV cache compression methods (quantization, low-rank approximations, and more), and an interactive Colab demonstrated upgrades using models like SAM2, KOSMOS2.5, and Florence-2, with fine-tuning support on the way.

## Showcases & Demos
Demos spotlighted practical reasoning and community creativity. A K2-Think chat app built with Anycoder lets users experience the 32B model’s reasoning live. Projects from the Nano Banana Hackathon went open source for easy remixing in AI Studio. A nostalgic look at original Photoshop 2.5 install disks made the rounds, bridging early digital creativity with today’s AI era.

## Discussions & Ideas
Conversation centered on how to deploy AI effectively and responsibly. Many argued the biggest opportunity lies in meeting users on their existing devices with on-device workflows, and that agentic RAG will unlock new application patterns. New findings warn that weaker models can degrade multi-agent debate performance, sometimes making a single strong model more reliable. Research suggests supervised fine-tuning can cause more catastrophic forgetting than reinforcement learning—key for continual learning. Market analysis noted the coding AI space fragmenting into distinct product categories, with fierce “coding agent wars” fueled by strong, low-cost open-weight models. Benchmarks and commentary highlighted compact models rivaling giants, while practitioners emphasized that imagination and specification—not tooling—often limit creative outcomes. Additional takes explored training-time “SEO” to embed brands into model priors, agents powering interactive frontends across OSS stacks, and the rise of new AI-era roles such as codebase cleanup specialists.

## Memes & Humor
A wave of tech nostalgia resurfaced with vintage Macintosh install disks for Photoshop 2.5, offering a lighthearted contrast to today’s rapid AI progress.

