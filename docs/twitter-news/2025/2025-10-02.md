Summary:
## News / Update
Acquisitions, funding, launches, and policy moved fast this week. Perplexity acquired Visual Electric, which will wind down, while Salesforce adopted Cline’s architecture to bring autonomous coding to its Agentforce Vibes platform. Moonlake AI raised $28M to power real-time simulations and gaming, and Modal secured new funding to scale AI infrastructure. OpenAI launched Sora 2 and is expanding invites with tighter daily limits as demand ramps. The White House tasked NIST to benchmark U.S. AI against global rivals, and Microsoft unveiled an Agent Framework in Azure AI Foundry for managing multi-agent systems. Google is bringing Gemini to Nest devices, and Meta faced scrutiny over chatbot safeguards for minors. On robotics, Amazon FAR reported a leap in humanoid agility, and Fourier began shipping its friendly Baymax robot; China’s LimX Robotics also reached surprising parity with top players. Community events were vibrant, with Google’s Nano Banana Hackathon awarding $400,000 to 50 winners and OpenAI’s GPT-5 x Codex hackathon energizing NYC. The Alignment Institute performed a pre-deployment safety evaluation of Claude Sonnet 4.5, sharing learnings to improve system safety.

## New Tools
Fine-tuning and agent tooling saw major upgrades. Tinker launched a flexible API and laptop-first workflow that abstracts GPUs for synthetic data generation and distributed fine-tuning, with early users reporting state-of-the-art results using less data; Redwood Research is already applying it to long-context control challenges. Document intelligence got easier with Mixedbread Search’s multilingual/multimodal beta, LlamaAgents’ one-click deployment of document agents, and Llama Index + Composio’s AG-UI Canvas starter kit for full-stack agent apps. Audio models advanced with Hume’s Octave 2 (faster, multilingual, multi-speaker) and new expressive text↔audio models, plus LiquidAI’s LFM2-Audio (1.5B, real-time, on-device). Robotics and safety tooling stepped up with Amazon FAR’s OmniRetarget for high-quality, interaction-preserving motion data and a new deepfake detector (DeeptraceReward) that catches 94% of AI-generated videos. Business users got three new analytics agents, while a lightweight Apple Ferret-UI Lite enables on-device GUI agents. A new app compresses and transcribes long videos locally using AssemblyAI and Gemini Flash for near-instant turnarounds.

## LLMs
Model performance and research pushed boundaries across modalities. Claude Sonnet 4.5 outpaced its 4.0 predecessor in coding speed, challenged top-tier models on speed and quality, and led creative/longform writing benchmarks, though users also reported jailbreaks that highlight ongoing safety tradeoffs. Math reasoning surged as Gemini 2.5 integrated with Goedel-Prover V2 to set new Putnam SOTA, and the Hilbert Agent, built on Goedel-Prover, topped the leaderboard by a wide margin. Efficiency themes dominated: DeepSeek V3.2 cut reasoning tokens dramatically, while the compact QuestA set new SOTA for 1.5B-parameter reasoning via RL scaffolding. GLM-4.6 arrived with aggressive cost savings and strong frontend coding wins (with some scaling caveats), and a broader wave of releases (e.g., Qwen3-VL) expanded developer choice. OpenAI’s Codex showed strong real-world CLI and coding performance. Research milestones included DeepMind’s AlphaEvolve discovering new results in complexity theory and a MENLO benchmark to evaluate multilingual capabilities across 47 languages. On accessibility, Apriel-1.5-15B-Thinker delivered complex reasoning on a single GPU, Tencent’s 80B HunyuanImage 3.0 surged in open-source rankings, and a biologically inspired Dragon Hatchling model reached GPT-2-level performance with a focus on interpretability.

## Features
Several mature products gained notable capabilities. Google’s new wired NestCam Outdoor uses on-board Gemini to deliver richer alerts, video summaries, and natural-language search across footage. GitHub Copilot added a CLI “/model” flag and auto model selection in VS Code to better match tasks to models. Codegen integrated with GitHub, Slack, and Linear to generate code and PRs on demand. Local and backend performance jumped as Osaurus integrated swift-transformers for faster macOS inference, NVIDIA optimized Ollama for RTX AI PCs to speed local LLMs, and vLLM added official support for encoder-only models like BERT to accelerate text understanding workloads.

## Tutorials & Guides
Practical resources emphasized smarter prompting and deployment. A guide debunked common RAG myths, detailing advanced indexing strategies that boost retrieval relevance. A step-by-step tutorial showed how to serve open models with vLLM via Hugging Face Inference Endpoints. Anthropic’s deep-dive on context versus prompt engineering offered actionable insights for getting more from LLMs. Developers also got a thorough explainer on multi-agent systems and a slide deck surveying open-source multimodal tools on Hugging Face. The “Hands-On Generative AI” book expanded to Korean, broadening access to foundational transformer and diffusion techniques.

## Showcases & Demos
Generative video and creative pipelines impressed. Sora 2 demos set a new bar for realistic, controllable world simulation, while Veo 3 highlighted zero-shot reasoning over physical interactions. Creators used Kling 2.5 Turbo and Seedream 4K to build coherent worlds in minutes, and tools like Lucid Origin compressed the idea-to-video timeline to mere minutes. A Gemini-powered collaboration translated Ross Lovegrove’s design aesthetic into a 3D-printed prototype, and Moondream 3 previews reminded viewers that what models miss can be as important as what they detect—showcasing the nuance required in visual reasoning.

## Discussions & Ideas
Research and industry debates centered on how we train, tune, and deploy AI. New work emphasized learning from real user interactions (RLHI), optimizing prompts before RL for stronger gains, and the risks of RL with poorly designed prompts that harm instruction following. Theoretical advances explored calibrated reward, the importance of mid-training dynamics, and “central flows” explaining optimizer behavior at the edge of stability. Studies showed RL helps compose atomic skills and that residual off-policy RL boosts real-world humanoid manipulation; LoRA often rivals full fine-tuning, and training inside world models can accelerate learning. Proposals like “Humanline” training aim to match human perception to cut costs, while aligning visual encoders as tokenizers improved diffusion models’ latent spaces. Community threads dissected GRPO’s significance, questioned whether RL startups need ex-lab founders to raise capital, and weighed bubble risks against continued optimism for OpenAI. With only 11% of Python developers regularly using coding agents, adoption still trails capability. Broader debates asked whether GPUs should prioritize societal value (medicine/education) over entertainment, and warned that increasingly real-time, lifelike AI content could blur the line between memory and manufactured media. Open-source models also earned praise for strong cybersecurity evaluations.

## Memes & Humor
A viral satire skewered AI priorities by imagining OpenAI in 2027 turning down cancer research because demand for short-form video kept GPUs saturated—fueling tongue-in-cheek debates about where AI effort should be focused.

