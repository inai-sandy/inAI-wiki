Summary:
## News / Update
Tech and policy intertwined this week: major platforms reportedly spent over $100M lobbying on U.S. AI rules, export controls, and data center policy, signaling intensified industry influence over regulation. NVIDIA extended its dominance with record data center revenues and unveiled its next-generation Vera Rubin architecture to boost large-scale throughput and efficiency. Consolidation and capital flowed: Anthropic acquired Vercept to strengthen Claude’s computer-use skills; defense AI firm Chariot raised $34M to scale battlefield systems; Citi made a strategic investment in Japan’s Sakana AI. Research infrastructure and community building accelerated, with Google DeepMind partnering with Align on global AMR biology datasets, Tinker grants opening to speed open-weight LLMs, and new gatherings announced, including ControlConf 2026 and the inaugural Voices of Voice AI event. The UK continued to outpace Europe in creating AI unicorns despite warnings about conservative pension capital. Anthropic updated its Responsible Scaling Policy with deeper transparency and new threat modeling. Data practices stayed in the spotlight amid the DeepSeek/Claude scraping controversy, prompting releases of large, redacted chat corpora. OpenAI added a high-profile hire to Labs, and multiple teams opened PhD opportunities in search and RL with LLMs.

## New Tools
A wave of developer- and researcher-focused tooling landed. Perplexity introduced Computer, an all-in-one workspace that orchestrates many models in parallel with files, tools, and memory—already demonstrating parity or better against costly incumbents. mjlab and Marimo each paired with SkyPilot to let users spin up GPU instances, sync code, run multi-GPU training or notebooks, and tear down with a single command. A unified chat SDK entered public beta to target Slack, Teams, Discord, Google Chat, and more from one TypeScript toolkit. LangChain’s new deepagents-acp library turns any agent into an ACP server for IDE-agnostic workflows and reduced vendor lock-in. TranslateGemma brought fast, fully local browser-based translation across 55 languages via WebGPU. LM Link delivered encrypted remote access to LM Studio deployments through a Tailscale integration. New data and evaluation resources arrived too: CoderForge-Preview offers 258k labeled agent coding traces to boost pass rates, and NanoKnow benchmarks what LLMs truly absorbed during pretraining versus what they retrieve externally. SparkMe debuted adaptive AI interviewing for qualitative research, while Simile AI highlighted major cycle-time reductions for enterprise studies.

## LLMs
Model competition intensified across speed, efficiency, and capability. Alibaba’s Qwen 3.5 family expanded rapidly—Flash (35B) challenged larger peers, Medium improved efficiency, new variants topped HLE, a 27B model led on key exams, a 35B-A3B build enabled stable local agent loops on 32GB RAM, and a 3D model advanced novel-view camera generation. xAI’s Grok 4.20 beta surged to #1 on Search Arena and climbed text leaderboards. OpenAI’s GPT-5.3 Codex posted standout coding results (including state-of-the-art IBench scores) amid reports it’s the first fully Blackwell-trained frontier model, with big gains in visual detail and code understanding. Google’s Gemini 3.1 Pro made a major jump, while Anthropic’s Claude swept code leaderboards. Locally, a 24GB VRAM setup matched Sonnet 4.6 on ts-bench, and China’s open-source stacks closed in on Sonnet-class performance, with labs like Stepfun shining in math. Efficiency frontiers moved fast: claims of 3B-parameter models beating 22B emerged; Mercury 2, a diffusion-style reasoning LLM, set new throughput marks around 1,000 tokens/sec; and labs reworked attention to handle million-token workflows at scale.

## Features
Core products gained meaningful capabilities. Android is getting Gemini-powered automations, smarter Circle to Search, and scam detection, while Circle to Search now identifies multiple objects in one shot. Google’s Flow added seamless image generation, editing, and animation for creative work. GitHub Copilot’s CLI graduated to general availability with a new research mode that maps and analyzes large repos. Multimodal retrieval matured as systems read text directly from images to mix document and visual search. TranslateGemma enabled fully offline, browser-based translation across dozens of languages. Notion’s evolving agents are displacing rivals inside startups by automating planning and operations. Agents began self-reporting their own failures, improving reliability monitoring; LM Link made it simple to securely operate local models remotely; and broader demos showed agents operating smartphones and apps end to end.

## Tutorials & Guides
Fresh learning resources spotlight agent design and frontier research. New “Agentic Engineering Patterns” chapters share best practices for building production-grade agents like Claude Code and Codex. Weekly research roundups distilled advances in multi-agent communication, delegation methods, new learning algorithms with LLMs, agent reliability, and AI safety—useful for teams upgrading agent stacks and evaluation pipelines.

## Showcases & Demos
AI crossed new thresholds in autonomy and embodied competence. DeepMind’s Aletheia autonomously solved six of ten FirstProof math problems, and an OpenAI internal model produced a new solution to the long-standing Erdős #846—evidence that agents can contribute to formal scientific discovery. Coding agents demonstrated near-human automation: Claude Code reconstructed a working Slack-like app from recordings, and Cloudflare co-built a 94% Next.js-compatible framework within a week. In robotics and simulation, NVIDIA showcased a dexterous humanoid trained from 20,000+ hours of human video, while projects like Genie and emerging world models delivered responsive, physically grounded simulation for training; Meta’s V-JEPA 2 further hinted at brain-like video world modeling and controllability. Security research advanced with AgenticRed’s evolutionary red-teaming finding attack strategies beyond human intuition. Generalization frameworks like Hybrid-Gym and methods such as Reflective Test-Time Planning showed practical ways to convert agent errors into learning gains. Anthropic’s retired Opus 3 even reemerged as a writing persona, underscoring creative, human-like expression from modern models.

## Discussions & Ideas
Debates sharpened around control, reliability, and the future of software. Voluntary development slowdowns are losing steam, with growing calls for stringent regulation; observers argue that principals and culture at labs like Anthropic can shape a model’s enduring “character.” New studies question how we measure progress: capability is racing ahead while reliability gains remain modest; irrelevant context can sharply degrade safety performance; and long-horizon failures often stem from agent design, not just missing knowledge—pointing to the need for stronger benchmarks and evaluation. Developers report a tipping point since December: coding agents can now autonomously create and clone complex apps, forcing leaders to rethink how software companies operate; many argue the best dev tools must “build themselves” by dogfooding. Broader societal concerns mounted: mass surveillance risks chilling speech, the prospect of AI weapons that obey illegal orders alarms ethicists, and algorithmically amplified true-crime content highlights offline harms. Meanwhile, the community pressed for more open datasets to fuel the next training leaps and debated product regressions, with some finding recent real-time conversational models less natural than expected.

