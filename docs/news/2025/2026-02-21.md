ğŸ“° AI News Daily â€” 21 Feb 2026

TL;DR (Top 5 Highlights)
- Googleâ€™s Gemini 3.1 Pro tops ARC-AGI-2 with 77.1% and lands a developer preview via the Interactions API, signaling stronger enterprise reasoning and workflow automation.
- Hugging Face welcomes the llama.cpp/GGML team, elevating open-source, on-device inference and recognizing Georgi Gerganovâ€™s foundational contributions to local AI.
- Anthropic debuts Claude Code Security, finding nontrivial vulnerabilities at scale and proposing patchesâ€”early results surface hundreds of bugs across major open-source projects.
- Throughput leaps: specialized chips and custom Taalas hardware hit ~17,000 tokens/sec on small LLMs without liquid cooling, foreshadowing drastic latency and cost reductions.
- Governments mobilize on AI governance: U.S. Treasury issues a banking AI risk framework, while NIST launches a standards push for interoperable, trustworthy agentic AI.

ğŸ› ï¸ New Tools
- Anthropicâ€™s **Claude Code Security** scans entire codebases to catch complex, often-missed vulnerabilities, then suggests patchesâ€”raising baseline software security for enterprises and open source maintainers alike.
- **Claude Code Desktop** upgrades add live app previews, PR reviews, and CI triageâ€”keeping code reviews flowing in the background and shrinking feedback loops for engineering teams.
- **OpenClaw** introduces agents with memory, skills, and rules as editable Markdown, making capabilities transparent, versionable, and easy to audit or extend without heavyweight orchestration.
- **agent-browser** adds pixel-diff visual regression checks, enabling resilient web automation that detects subtle UI changes while cutting token use and flaky selectors.
- **Pika AI Selves** launches persistent, personalized agents that learn user preferences and contextâ€”aiming for dependable â€œextensions of youâ€ instead of disposable one-off chat sessions.
- **Replit Animation** turns text prompts into shareable videos, pushing video creation to mainstream users and offering creators a rapid path from idea to publishable content.

ğŸ¤– LLM Updates
- **Google DeepMind Gemini 3.1 Pro** hits 77.1% on ARC-AGI-2 and arrives in dev preview via the Interactions API; a stronger **Gemma** for edge devices is also teased.
- **Anthropic Claude 4.6 Opus** sets a new mark on long-horizon software tasks (~14.5 hours), while **Sonnet 4.6** jumps near top-tier coding and improves â€œWeirdMLâ€ reasoning.
- **Qwen3.5** posts leading vision results and ships **Qwen3-Coder-Next** via API, while **DeepSeek V3.2** narrows coding gaps with Western leaders across compact footprints.
- Efficiency surges: a new model claims ~1,200 tokens/sec, and specialized hardware reaches ~17,000 tokens/secâ€”slashing latency and serving costs for small, responsive LLMs.
- Scoreboards reshuffle: SWE-bench scoring fixes narrow gaps with original reports; a clever exploit exposes a coding-agent benchmark vulnerability, prompting stronger evaluation hygiene.
- Method advancesâ€”flow maps, continuous language diffusion, sparsity and distillation (e.g., SpargeAttention2), temporally autoregressive video, and Unified Latentsâ€”deliver faster generation and record-low ImageNet-512 FID.

ğŸ“‘ Research & Papers
- **NVIDIA** releases a substantial research package with open code and checkpoints, accelerating reproducibility and real-world transfer for practitioners building on cutting-edge techniques.
- The **Agent Data Protocol** dataset doubles to 3.2M examples and earns an ICLR oral, supplying richer supervision for agent planning, tools, and cross-episode memory.
- **DreamDojo** debuts an open simulation world model for robotics, enabling pixel-to-policy training and advancing generalizable, real-world robot learning benchmarks.
- Evaluation shake-ups highlight reliability: SWE-bench rescoring adjusts standings, a popular coding-agent benchmark shows exploitability, and â€œduplicate promptsâ€ emerge as a simple, effective performance hack.
- **METR** reports agentic models sustaining longer, more complex task chains, while world-model research momentum growsâ€”seen by many as key to robust reasoning beyond text.

ğŸ¢ Industry & Policy
- The U.S. **Treasury** publishes an AI Risk Management Framework and Lexicon for global banks, offering practical guidance to manage cybersecurity, compliance, and model risk across financial services.
- **NIST** launches a standards initiative for agentic AI, aiming for interoperable, trustworthy agents across government and enterpriseâ€”advancing U.S. leadership and public trust.
- **NVIDIA** reportedly plans a multi-billion investment in **OpenAI** over several rounds; figures vary ($30Bâ€“$100B), underscoring intensifying hardwareâ€“model alignment in the AI race.
- **Reliance/Jio** commits $110B to Indiaâ€™s AI infrastructure, green energy, and affordable appsâ€”targeting multilingual solutions in healthcare and education to scale inclusive AI access.
- **Accenture** makes regular AI tool use mandatory for senior promotions, accelerating upskilling across 500k+ staff and signaling a new baseline for AI fluency in leadership.
- Public-interest oversight grows: **Canada** backs the next phase of Scientist AI, while new independent auditor **Averi** pushes rigorous, third-party safety reviews for advanced AI systems.

ğŸ“š Tutorials & Guides
- **Google** launches a practical AI Professional Certificate with 20+ labs focused on production workflows, app building, and job-ready skills for data and software teams.
- **Modularâ€™s Mojo** deep dives GPU performance via array-broadcasting puzzles, while a CuTe-layouts walkthrough yields a GEMM kernel beating cuBLASâ€”hard-won insights for systems engineers.
- **DSPy Weekly** ships optimize_anything and GEPA, with explainers on recursive language models and scaling agents in real fintech environmentsâ€”bringing evaluation discipline to production.
- A â€œvibe-codingâ€ extraction demo shows how to turn messy documents into structured data using natural languageâ€”spotlighting data-centric pipelines and the rising importance of eval literacy.

ğŸ¬ Showcases & Demos
- **Taalas** demos Llamaâ€‘3.1 inference at ~17k tokens/sec on custom airâ€‘cooled hardware, illustrating how specialized designs can upend latency and serving economics.
- **FireworksAI** publishes transparent runs of **MiniMax M2.5**, enabling applesâ€‘toâ€‘apples comparisons and bolstering community trust in thirdâ€‘party benchmarks.
- **LlamaCloud** workflows convert receipt photos into structured financial insights, a practical agenticâ€‘vision pipeline turning unstructured images into reliable analytics.
- **Replit Animation** fuels oneâ€‘click, shareable video creationâ€”creators spin up viralâ€‘ready clips without editing stacks, broadening access to AI video storytelling.
- **PokeBench** pits models in real N64 PokÃ©mon Stadium 2 matches, stressâ€‘testing planning, adaptability, and multiâ€‘step reasoning under pressure.
- **YouTube** rolls out a conversational AI assistant on smart TVs and consoles, enabling realâ€‘time Q&A about videos and boosting leanâ€‘back engagement.

ğŸ’¡ Discussions & Ideas
- Benchmarks vs. reality: **Gemini** posts big wins yet shows narrower realâ€‘world behavior, while **Claude** pushes longer, more agentic workflowsâ€”highlighting training tradeâ€‘offs and conservative RL effects.
- Autonomy and safety: the â€œselfâ€‘evolution trilemmaâ€ questions safe closedâ€‘loop selfâ€‘improvement; new data shows agents ask humans for help more often than expected under real constraints.
- Security and accountability: fake â€œGeminiâ€ chatbots fuel crypto scams, and internal AI tools tie to AWS outagesâ€”renewing calls for strong access controls, audits, and incident transparency.
- Builder priorities: stability and evaluations beat buzz. Teams treat code like versioned model artifacts; smaller models plus smart prompts rival expensive upgrades in costâ€‘sensitive stacks.
- Dataâ€‘centric culture: evaluation literacy and data science outpace prompt tinkering; UI trends favor â€œfiles over apps,â€ improving portability, provenance, and collaborative review.
- AI in finance and society: leaders tout stablecoins as default rails for AIâ€‘agent payments; defense access and ambient AI devices spark debates on privacy, governance, and accountability.

## Source Credits  
Curated from 250+ RSS feeds, Twitter expert lists, Reddit, and Hacker News.